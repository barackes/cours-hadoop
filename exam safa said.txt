citez 3 composantes de l’écosystème Hadoop: Décrivez les succinctement, expliquez votre choix
HDFS: c'est le systéme de fichier distribué d'hadoop .Il gére le stockage distribué des données sur les noeud du cluster de façon complétement tolerente au panne
Hive: c'est une infrastructure semblable à un datawarehouse possede un language de requete hiveql (basé sur sql) qui permet d'adresser des requete sur HDFS.Choix: car c'est un language d'abstaction permettant au analyste métier d'exploiter les donnée sur HDFS à travers des requete
mapReduce :framework open source java, permettant la manipulation des données dans un environnement distribué. Il est composé de 3 phase principales (map, shuffle et le reduce) choix: c'est le modele de calcul utilisé par hadoop1 


Qu’avez vous retenu de HDFS: architecture, fonctionnement, éléments de conception, points fort/faible
HDFS fonctionne en mode master/slave et shared nothing :
Name node: gére les metadonnées du systéme de fichier (ne stocke pas les données ) et sait ou sont repartie les block de données d'un fichier stocké sur hdfs
Data node :contient les données et c'est surlequel s'éxecute les taches de map et reduce

Quand un client sollicite Hadoop pour récupérer un fichier, il fait une demande au name node. Ce Namenode va indiquer au client quels sont les Datanodes qui contiennent les blocs.(livre au client un token contenant un pointeur vers les datanode et les block de donné)
fonctionnement pour stocker les block de donnée sur le cluster (staging pipline):
1-le fichier est découpé en block de 64mo  par HDFS
2-le name node verifie dans les metadonnées de hdfs les noeud qui possedent des block libre sur leur disque dure et assigne les block de données à ces noeuds
3-HDFS créé un fichier temporaire contenant les block de donnés et la liste des data node auquel ils sont affectées
4-le data node stocke les block de donnée le concernant et fait suivre ce fichier au noeud suivant. 
Faiblesse :le name node constitu un single point of failur (spof) ,en effet s'il tombe en panne on ne peux plus acceder au systémes de fichier.
Point Fort: HDFS est un FS extensible, il est possible d'ajouter des noeuds au cluster et de reconfigurer le namenode 

Qu’avez vous retenu de Spark: architecture, fonctionnement, éléments de conception, points fort/faible
spark est un  modele de calcul distribué (in memory) utilisé pour les application itérative (de machine learning) (permet la reduction du temps de latence puisqu'il n'y a plus d'aller retour vers le disque dure de chaque noeud)
En spark on manipule des RDD (resilient distributed dataset) : collection d'objet accessible en lecture seul partitionné et distribué à travers les noeud du cluster qu'on peut regénerer à l'aide du couple (parent,opération)
DAG Direct Acyclic Graph: ensemble de tache regroupé en stage (stage :la repartition des donnée change sur les noeud :les donnée se deplace d'un noeud à un autre suite à un shuffle par exemple)
DAG peut avoir plusieur niveau et optimise l'execution des job

Peut on faire du spark sans HDFS? et sans YARN?
On peut utilisé spark sans hdfs (récuperer les donnée directement d'un fichier json ou de base de données hive)
spark peut etre deployé en mode standalone, yarn, mesos
on peut donc utlisé spark sans yarn qui est uniquement un gestionnaire de ressource 



Quelles sont les differences entre Hadoop v1 et Hadoop v2?
-au niveau de la securité 
-le modéle de calcul (hadoop1 un seul modele de calcul peut etre executé qui est le mapReduce, hadoop2 plusieur modele de calcul au choix) 
-la gestion des ressource (hadoop 1 le job tracker planifie l'execution des tache et fait le suivi en meme temps, dans hadoop 2  on a plusieur entité comme dans yarn le resource manager qui gére l'utilisation des ressource, applcation master qui négocie les ressource avec le ressource manager et le node manager qui surveil les ressource et envoi des rapport sur le statut d'execution au ressource manager)
-Dans hadoop 1 l'allocation des ressource se fait selon le nombre de tache map reduce (de cette facon tous les noeud ne sont pas forcement utilisé) hadoop2 optmise plus l'utilisation des ressource








