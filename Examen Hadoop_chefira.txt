Examen Hadoop : 
•	citez 3 composantes de l’écosystème Hadoop: Décrivez les succinctement, expliquez votre choix
•	Qu’avez vous retenu de HDFS: architecture, fonctionnement, éléments de conception, points fort/faible
•	Qu’avez vous retenu de Spark: architecture, fonctionnement, éléments de conception, points fort/faible
•	Peut on faire du spark sans HDFS? et sans YARN?
•	Quelles sont les differences entre Hadoop v1 et Hadoop v2?


Question 1 : J’ai choisi 3 composants de l’écosystème Hadoop ci-dessous : 
1)	Pour le système de fichiers distribué j’ai choisi HDFS,  qui est un système de fichiers distribué et la couche native de stockage et d'accès à des données d'Hadoop. Il permet de stocker des fichiers de très grande taille dans un cadre distribué. 
2)	Le gestionnaire de ressource j’ai choisi  YARN , car il permet de faire coexister dans la même installation Hadoop plusieurs modèles de calcul distribué. Il reprends une partie des taches qui étaient effectuées par MapReduce. En effet, YARN crée pour chaque job du modèle de calcul un container auquel il alloue des ressources et suit l’exécution de ces différentes ressources. Par exemple, si l’on exécute un job Spark et un job MapReduce,  YARN va les encapsuler chacun dans un container différent, allouer des ressources précises à chaque container, et suivre l’exécution des containers dans les nœuds de données. 

3)	Spark : C’est un framework de calcul Open source, qui a la particularité d’ écrire les données en RAM. Je l’ai choisi car il permet une plus grande rapidité de traitement des calculs. 
Question 2 : 
Qu’avez-vous retenu de HDFS: architecture, fonctionnement, éléments de conception, points fort/faible
HDFS :  Architecture Dans un cluster, où les données et les services sont stockées sur plusieurs machines différentes, HDFS fonctionne selon un principe maître/esclaves classique : les données y sont stockées sur les datanodes (esclaves) tandis que les localisations des blocs de données sont répertoriées par le namenode (maître)
Principe de Lecture d’un fichier :
1.	L’utilisateur indique au namenode qu'il souhaite lire un fichier.
2.	Le name node indique la taille du fichier ainsi que les différents data nodes contenant les blocs qui composent ce fichier.
3.	Le client  récupère chacun des blocs sur l'un des data nodes.
4.	Si un des datanodes est indisponible, Le client en contacte un autre.

   Principe d’écriture d’un fichier : 
1.	Le client indique au namenode qu'il souhaite écrire un bloc.
2.	Le namenode retourne au client le datanode à contacter.
3.	Le client envoie le bloc au datanode.
4.	Les datanodes répliquent les blocs entre eux.
5.	Le cycle se répète pour le bloc suivant.

Avantage et inconvénient HDFS : 
Le système de fichiers est distribué sur plusieurs  serveurs, et chaque nœud stocke une partie du système fichier. Pour éviter le risque de perdre des données, chaque donnée est stockée à trois emplacements. 
HDFS évite également la congestion de réseau en privilégiant le déplacement des opérations plutôt que le déplacement des données. Ainsi, les applications peuvent accéder aux données à l’endroit où elles sont entreposées. Dernier point fort : sa portabilité. Il peut fonctionner sur différents types de commodity hardwares sans aucun problème de compatibilité.
Inconvenient : 
Un des problèmes est stockage des fichiers de petite taille qui  occupe inutilement de l’espace et augmenter la latence des traitements. 
Question 3 : 

Question 4 : Spark : 
La couche d'abstraction que fournit Spark permet de ne pas se soucier de l'architecture sur laquelle tourne une  application. Cela nous permet de prototyper des applications en local avant de les envoyer vers un cluster de plusieurs machines pour traiter des données de taille plus conséquente sans vous préoccuper du changement d'architecture. 
La répartition des données se fait de la facon suivante, les données sont découpées en partitions. Chaque partition est assignée à un des executors. Le traitement d'une partition représente une tâche : c'est la plus petite unité de traitement de données que nous allons voir. Un cluster Spark ne peut traiter qu'une tâche à la fois par executor, et en général il y a un executor par cœur de processeur. Par ailleurs, la taille d'une partition doit rester inférieure à la mémoire disponible pour son executor. Le choix du nombre de partitions est donc crucial, puisqu'il détermine le nombre de tâches qui seront réalisées de manière concurrente sur le cluster. Nous nous pencherons plus précisément sur ce point dans le chapitre sur le déboguage et l'optimisation d'applications Spark.

Un ensemble de tâches réalisées en parallèle, une par partition d'un RDD, constitue une étape (stage). Toutes les tâches d'une étape doivent être terminées avant que l'on puisse passer à l'étape suivante. Un job Spark est composé d'une succession d'étapes ; la progression d'un job peut donc être mesurée au nombre d'étapes qui ont été réalisées. Un job Spark est créé pour chaque action qu'on réalise sur un RDD.

Question 4)
 Peut on faire du spark sans HDFS? et sans YARN?
On peut faire Spark sans HDFS , en mode standAlone. 
Spark peut fonctionner en se connectant à des cluster managers de types différents :On peut utiliser Spark sans HDFS
1)	le cluster manager autonome de Spark
2)	Yarn 
3)	Mesos
4)	Kubernetes 


Question 5 ) 
Quelles sont les differences entre Hadoop v1 et Hadoop v2?

Hadoop2 réponds à certaines limites que connait Hadoop1 
Transformer un algorithme en MapReduce demande beaucoup d'effort
De même, pour traiter des problèmes complexes, les deux étapes MAP et REDUCE ne suffisent pas, il est très souvent nécessaire d'enchaîner des séquences de MapReduce ce qui est très coûteux car cela nécessite de demarrer un job MapReduce à chaque fois.
 Yarn arrive pour répondre au problème du Map Reduce, car Le job tracker a une double responsabilité :Il doit gérer les ressources du cluster et il doit ordonnancer les jobs. Ce qui pose un problème si le tracker est défaillant. Yarn permets de gérer les ressources.
Yarn un framework permettant d'exécuter n'importe quel type d'application distribuée sur un cluster Hadoop, pas uniquement les applications MapReduce et propose en effet de séparer la gestion des ressources du cluster et la gestion des jobs MapReduce, permettant ainsi de généraliser cette gestion des ressources à d'autres applications. L'idée principale est de considérer que les nœuds ont des ressources (mémoire et CPU) qui seront allouées aux applications quand elles le demandent.
